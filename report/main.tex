\documentclass{template/acm_proc_article-sp}

\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{color}
\usepackage{siunitx}
\usepackage{csvsimple}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{float}

\usepackage{amssymb}
\usepackage{pifont}
\newcommand{\markx}{\ding{53}}
\newcommand{\marko}{\ding{108}}

\begin{document} 

\title{Image tamper detection based on demosaicing artifacts}

\numberofauthors{2} 
\author{
% 1st. author 
\alignauthor
Matja≈æ Mav\\
       \affaddr{Faculty of Computer and Information Science, University of Ljubljana}\\
       \email{mm3058@student.uni-lj.si}
% 2nd. author
\alignauthor
Klemen Jesenovec\\
       \affaddr{Faculty of Computer and Information Science, University of Ljubljana}\\
       \email{kj9807@student.uni-lj.si}
}

\maketitle
\begin{abstract}
This paper reviews and summarizes research done on image tampering detection
using a color filter array demosaicing technique. The algorithm and it's features are
explained and implemented in MATLAB. The algorith is tested on sample data and results
are discussed.
\end{abstract}

\keywords{Image tampering, digital forensics, color filter array}

\section{Introduction}
This paper aims to review and summarize a paper about image tamper 
detection in the field of digital image forensics~\cite{dirik2009image} (later referred as referenced paper).

The paper classifies image tampering into three groups: 
\begin{description}
    \item[Targeted Tamper Detection] Which focus on detecting specific groups of 
    tampering such as re-compression, cloning, resizing, etc. 
    \item[Universal Tamper Detection] Which can only determine if the image
    was tampered with or not.
    \item[Localized Tamper Detection] Which can identify parts of the image 
    that were tampered with.
\end{description}

The paper describes a Color Filter Array (CFA) demosaicing based tamper detection
that can detect both local and universal tempering.
The method works due to the fact that image tampering usually alters CFA demosaicing
artifacts in a way that can be detected and can thus detect a wide range of tampering
techniques. 

In the following sections we explain CFA, summarize the technique presented 
in the referenced paper and present our own implementation in MATLAB.
Finally, we discuss the results and limitations of our implementation and compare it
to the results in the referenced paper.

\section{Color filter array}
Color filter array is a grid of small color 
filters put over an image sensor.
The filters are needed due to the sensor's inability to capture wavelength 
information and thus cannot distinguish between different colors.
The CFA filters out specific colors before the light arrives at the image sensor.
This enables cameras to capture color information.

There are many types of CFA although the Bayer filter is most commonly used and is 
illustrated in figure~\ref{img_4_bayer_filters}.
It uses one red, one blue and 2 green filters per pixel. 
Green being used twice due to human eye sensitivity to green color.

Other types of filters include a RGBE filter which also uses an emerald filter, a CYYM
filter which uses one cyan, two yellow and one magenta filter, a RGBW filter which also uses a white filter, etc.

The process of interpolating different sets of color information into a single image 
is called demosaicing.

\begin{figure}[H]
\centering
\includegraphics[trim=175 200 100 205,clip,width=0.46\textwidth]{report/results/4_bayer_filters.jpg}
\caption{Commonly used Bayer filters}
\label{img_4_bayer_filters}
\end{figure}

\section{CFA Interpolation}
CFA interpolation or demosaicing \cite{cfainterpolation2009,gunturk2005demosaicking} is the process of building a singe image from
multiple color sets. 
This can be achieved using simple interpolation techniques such as 
nearest-neighbor interpolation, bilinear interpolation, 
bicubic interpolation, spline interpolation, etc.

Advanced demosaicing algorithms using pixel correlation such as 
variable number of gradients, pixel grouping, adaptive homogeneity-directed
are out of scope of this paper.

Bilinear interpolation is used in this paper as it was also used in
the referenced paper. The referenced paper also states result do not
differ using bicubic interpolation.

In our MATLAB implementation we used interpolation implementation by S. Leszek \cite{cfainterpolation2009}.

\newpage
\section{CFA based features}
In this section we will review two CFA based features introduced in the paper \cite{dirik2009image}. The first feature (referred to as  $F_1$) mainly relies on the estimation of the source digital camera CFA pattern. And the second feature (referred to as $F_2$) relies on the source digital camera sensor noise.

Both of the features can be used in universal tampering detection and also when applied with sliding window in local tampering detection.

For both of the features we implemented algorithm in MATLAB. All code is available on the GitHub repository\\\textit{matjazmav/fri-1819-df-seminar}\footnote{\url{https://github.com/matjazmav/fri-1819-df-seminar}}.

\subsection{Feature 1: Pattern number estimation}
This feature is trying to estimate which CFA pattern was used by the source digital camera.

To estimate possible used CFA pattern, the image is first re-sampled with each of the CFA patterns (usually only 4 most commonly used that are illustrated in figure \ref{img_4_bayer_filters}) and then re-interpolated with the same CFA pattern. This steps are illustrated in figure \ref{img_f1_steps}. After that (3) MSE between the image and its re-interpolated part is calculated. For the image that is not tampered, one of the MSE values are expected to be significantly smaller from the others. If that is not the case, the image may have been post-processed.

We followed steps that are introduced in referenced paper and implemented MATLAB algorithm that estimates $F_1$ feature. Unfortunately we ware not able to reproduced the results that are described in there.

\begin{figure}[H]
\centering

\begin{subfigure}{0.23\textwidth}
    \includegraphics[trim=0 0 0 0,clip,width=\linewidth]{report/results/f1_steps_0.jpg}
    \caption{Original image}
\end{subfigure}
\hspace*{\fill}
\begin{subfigure}{0.23\textwidth}
    \includegraphics[trim=0 0 0 0,clip,width=\linewidth]{report/results/f1_steps_1.jpg}
    \caption{CFA filter}
\end{subfigure}

\begin{subfigure}{0.23\textwidth}
    \includegraphics[trim=0 0 0 0,clip,width=\linewidth]{report/results/f1_steps_2.jpg}
    \caption{Re-sampled image}
\end{subfigure}
\hspace*{\fill}
\begin{subfigure}{0.23\textwidth}
    \includegraphics[trim=0 0 0 0,clip,width=\linewidth]{report/results/f1_steps_3.jpg}
    \caption{Re-interpolated image}
\end{subfigure}

\caption{Steps taken in $F_1$ feature estimation. Original image (a) and selected CFA filter (b) are used to re-sample image. The re-sampled image (c) is then re-interpolated with the selected CFA filter (b). Final result is shown in (d).}
\label{img_f1_steps}
\end{figure}
\vfill\null

\subsection{Feature 2: CFA based noise analysis}
\label{sec_f2}
This feature analyses the source digital camera noise. If the image is CFA interpolated the variance of the CFA interpolated pixels is expected to be significantly smaller that the variance of non-interpolated pixels.

To calculate $F_2$ feature we need to follow this steps:
\begin{enumerate}
    \item Estimate sensor noise on the green channel of the image. First denoise image with level 1 wavelet denoising. Noise is defined as difference between image and corresponding denoised image.
    \item Calculate variance of the estimated noise of the interpolated $A_1$ and corresponding non-interpolated $A_2$ pixels.
    \item The final $F_2$ feature is calculated as maximum between both variance ratios (equation \ref{eq_f2}).
\end{enumerate}

\begin{align}
F_2 = max(\frac{var(A_1)}{var(A_2)}, \frac{var(A_2)}{var(A_1)})
\label{eq_f2}
\end{align}

Our MATLAB implementation of the $F_2$ feature extraction for the global tampering detection follows as:

\begin{lstlisting}[language=Matlab,basicstyle=\tiny,numberstyle=\tiny,numbers=left,numbersep=5pt]
function f2 = extract_f2(I)
% INPUTS
% I - RGB image
% OUTPUTS
% f2 - f2 measure

[h,w,~] = size(I);

G = double(I(:,:,2)); % extracted green color channel
Gd = wdenoise2(G,1);  % denoise image
N = G - Gd;           % extract image noise            

% resize green color mask
mask = logical(repmat([1 0; 0 1], ceil([h/2 w/2])));
mask = mask(1:h, 1:w);

A1 = N .* mask;       % extract non-interpolated noise vector
A2 = N .* ~mask;      % extract interpolated noise vector

% calculate f2 measure
vA1 = var(A1(:));
vA2 = var(A2(:)); 
f2 = max(vA1/vA2, vA2/vA1);

end;
\end{lstlisting}

With slight modification of upper implementation, lines 13 - 23 ware processed with sliding window (using function \verb blockproc), we ware able to calculate $F_2$ map and successfully localize tampering on the two images that ware used in referenced paper.

\section{Experiments}
We evaluated both of the features on dataset used in referenced paper \cite{dirik2009image}, copy-move dataset MICC-F220 dataset \cite{amerini2011sift} that contains 110 pristine and 110 tampered images and also on small dataset that we prepared\footnote{Available on the GitHub repository in folder \textit{resources/datasets/ours}.}.

Because of mostly unsuccessful results we also evaluated our implementations on the UCID dataset \cite{schaefer2003ucid}. UCID dataset contain uncompressed color images in TIFF image format, taken by Minolta
Dimage 5 digital colour camera (uses G - R - G - B CFA). Since referenced paper mentions that this two purposed techniques are strongly sensitive on used CFA, JPEG compression and resizing, we tried to tamper raw images with copy-move technique without resizing and using different compression levels saving into JPEG and PNG image format. Unfortunately we ware unable to produce tampered image that could be detected with our implementation.

\subsection{Local tampering detection}

As we described in section \ref{sec_f2}, we ware able to successfully replicate the local tampering detection on the images used in the referenced paper. The results of the our implementation are illustrated on the figure \ref{img_f2_localization}. Since our results are very similar to the results illustrated in the referenced paper we assume that our implementation is correct. 

Unfortunately we ware unable to successfully localize tampered regions on other datasets. 


\begin{figure}[H]
\centering

\begin{subfigure}{0.46\textwidth}
    \includegraphics[trim=275 300 200 250,clip,width=\linewidth]{report/results/f2_seagull_orig.jpg}
    \caption{Pristine coast image}
\end{subfigure}

\begin{subfigure}{0.46\textwidth}
    \includegraphics[trim=275 300 200 250,clip,width=\linewidth]{report/results/f2_seagull.jpg}
    \caption{Tampered coast image}
\end{subfigure}

\begin{subfigure}{0.46\textwidth}
    \includegraphics[trim=275 300 200 250,clip,width=\linewidth]{report/results/f2_subway_orig.jpg}
    \caption{Pristine subway entrance image}
\end{subfigure}

\begin{subfigure}{0.46\textwidth}
    \includegraphics[trim=275 300 200 250,clip,width=\linewidth]{report/results/f2_subway.jpg}
    \caption{Tampered subway entrance image}
\end{subfigure}

\caption{Local tampering detection with $F_2$ feature. Left images visualize $1/F_2$ map and right images are annotated where map is greater then threshold $T = 0.8$.}
\label{img_f2_localization}
\end{figure}

\subsection{Universal tampering detection}

Our implementation is not able to classify between pristine and tampered images. We tested bot of the features on MICC-F222 dataset and illustrated extracted feature values in figure \ref{img_f1_f2_universal}.

\begin{figure}[H]
\centering

\begin{subfigure}{0.46\textwidth}
    \includegraphics[trim=0 0 0 0,clip,width=\linewidth]{report/results/f1_results.jpg}
    \caption{Feature 1}
\end{subfigure}

\begin{subfigure}{0.46\textwidth}
    \includegraphics[trim=0 0 0 0,clip,width=\linewidth]{report/results/f2_results.jpg}
    \caption{Feature 2}
\end{subfigure}

\caption{Universal tampering detection with $F_1$ and $F_2$ features on MICC-F220 dataset.
\newline{\color{blue}\marko} pristine image \newline{\color{red}\markx} tampered image (copy-move)}
\label{img_f1_f2_universal}
\end{figure}

\section{Conclusions}
As seen in the results we were able to reproduce the results achieved in the 
referenced paper. However we were not able to detect tampering on other datasets.
This could be a result of improper post-processing done on the tested datasets such as: (1) use of an improper tampering technique (we mostly used copy-move, some of examples also included edge blurring and resizing), (2) use of too advanced image editing tool (we used Gimp and Adobe Photoshop), or (3) use of an improper compression levels and image formats. We were however successful in presenting and summarizing the techniques used.

\bibliographystyle{abbrv}
\bibliography{main}

\end{document}
